{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e68e79e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense,Dropout\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "from numpy import concatenate\n",
    "from pandas import read_csv\n",
    "from pandas import DataFrame\n",
    "from pandas import concat\n",
    "import math\n",
    "from tqdm.notebook import tqdm\n",
    "tf.random.set_seed(0)\n",
    "from sklearn.metrics import mean_absolute_error as mae\n",
    "from sklearn.metrics import mean_absolute_percentage_error as mape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05dcb301",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dataframe = pd.read_excel('D:\\\\Desktop\\\\akshat\\\\Internship_Stuff\\\\Dataset\\\\Forecasting_Data_Values\\\\test_5412_2.xlsx')\n",
    "print(dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7158ee37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the columns based on factors taken for Forecasting\n",
    "dataframe=dataframe.drop(columns=['NINO'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8b24a67",
   "metadata": {},
   "source": [
    "# Normalizing Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21b1ffc3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "values=dataframe.values\n",
    "print(values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bba7b8c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "values_spi=values[:,1]\n",
    "print(values_spi.shape,type(values_spi))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "721f3823",
   "metadata": {},
   "outputs": [],
   "source": [
    "values_spi=values_spi.reshape(-1,1)\n",
    "print(values_spi.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26bface9",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler=MinMaxScaler(feature_range=(0, 1))\n",
    "scaled = scaler.fit_transform(values_spi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55dafe08",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "v=values\n",
    "v[:,1]=scaled[:,0]\n",
    "print(v)\n",
    "values1=v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba7614e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_scaled = pd.DataFrame(values1)\n",
    "print(df_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8438ea81",
   "metadata": {},
   "source": [
    "# Adding Lookback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad133bde",
   "metadata": {},
   "outputs": [],
   "source": [
    "dX = []\n",
    "dY = []\n",
    "n_future = 1\n",
    "n_past = 6 #No of Past values for forecasting\n",
    "for i in range(n_past, len(df_scaled) - n_future +1):\n",
    "    dX.append(values1[i - n_past:i, 1:dataframe.shape[1]])\n",
    "    dY.append(values1[i + n_future - 1:i + n_future,1])\n",
    "dX, dY = np.asarray(dX), np.asarray(dY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db22e21f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(len(dX),dX.shape,len(dY),dY.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fdd48a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dX = np.asarray(dX).astype(np.float32)\n",
    "dY = np.asarray(dY).astype(np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a14e5588",
   "metadata": {},
   "source": [
    "# Training and Testing Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86e2b6bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(len(dX)-24)\n",
    "test_size = len(dX) - train_size\n",
    "trainX, testX = dX[0:train_size,:], dX[train_size:len(dX),:]\n",
    "print(len(trainX),trainX.shape,len(testX),testX.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "093812f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(len(dY)-24)\n",
    "test_size = len(dY) - train_size\n",
    "trainY, testY = dY[0:train_size,:], dY[train_size:len(dY),:]\n",
    "print(len(trainY),trainY.shape,len(testY),testY.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e2a6215",
   "metadata": {},
   "source": [
    "# Callback to prevent overfitting(Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbec5a52",
   "metadata": {},
   "outputs": [],
   "source": [
    "class myCallback(tf.keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        if(logs.get('loss')<0.0006):\n",
    "            print(\"\\nLoss is low so cancelling training!\")\n",
    "            self.model.stop_training = True\n",
    "callbacks = myCallback()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0734ba5b",
   "metadata": {},
   "source": [
    "# LSTM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2f87187",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(128, activation='relu', input_shape=(trainX.shape[1], trainX.shape[2]), return_sequences=True))\n",
    "model.add(LSTM(64, activation='relu', return_sequences=False))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "history = model.fit(trainX, trainY, epochs=100, batch_size=1, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f154e301",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainPredict = model.predict(trainX, batch_size=1)\n",
    "trainPredict = scaler.inverse_transform(trainPredict)\n",
    "trainY_2 = scaler.inverse_transform(trainY)\n",
    "model.reset_states()\n",
    "testPredict = model.predict(testX,batch_size=1)\n",
    "testPredict = scaler.inverse_transform(testPredict)\n",
    "testY_2 = scaler.inverse_transform(testY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b920f9be",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.plot(trainY_2)\n",
    "plt.plot(trainPredict)\n",
    "plt.legend(['observed','predicted'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc75475d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#extra stuff to  make proper graphs\n",
    "z=[]\n",
    "for i in range(0,25):\n",
    "    z.append(i)\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd86eb1e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.plot(testY_2)\n",
    "plt.plot(testPredict)\n",
    "plt.xticks(z)\n",
    "plt.legend(['observed','predicted'])\n",
    "plt.ylabel('SPI')\n",
    "plt.xlabel('Month')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eec09822",
   "metadata": {},
   "source": [
    "# Cheking the error scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd47b007",
   "metadata": {},
   "outputs": [],
   "source": [
    "#RMSE\n",
    "trainScore = math.sqrt(mean_squared_error(trainY_2[:,0], trainPredict[:,0]))\n",
    "print('Train Score: %.2f' % (trainScore))\n",
    "testScore = math.sqrt(mean_squared_error(testY_2[:,0], testPredict[:,0]))\n",
    "print('Test Score: %.2f' % (testScore))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14093d44",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preliminary stuff for other errors\n",
    "v=testY_2.copy()\n",
    "ob=[]\n",
    "for i in v:\n",
    "    ob.append(i[0])\n",
    "print(ob)\n",
    "v=testPredict.copy()\n",
    "pred=[]\n",
    "for i in v:\n",
    "    pred.append(i[0])\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5fe7d1f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Correlation score\n",
    "r = np.corrcoef(ob,pred)\n",
    "print(\" correlation:\")\n",
    "print(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe17ca58",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Mean Absolute Error\n",
    "m = mae(ob,pred)\n",
    "print('MAE:'+str(m))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e666be40",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Mean Absolute Percentage Error\n",
    "print('MAPE: '+str(mape(ob,pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4b73fbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Percentage fo Droughts predictied and Percentage of Predictions in 1 Drought Catecory\n",
    "dob=0\n",
    "dp=0\n",
    "diffok=0\n",
    "for i in range(0,len(ob)):\n",
    "    if ob[i]<=0:\n",
    "        dob+=1\n",
    "        if pred[i]<=0:\n",
    "            dp+=1\n",
    "            if abs(ob[i]-pred[i])<0.5:\n",
    "                diffok+=1\n",
    "print(\"Percentage of droughts predicted: \"+ str((dp/dob)*100))\n",
    "print(\"Percentage of Predicted drought with low disparity: \"+ str((diffok/dp)*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24d29878",
   "metadata": {},
   "source": [
    "# Extra Stuff for Feature Importance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35f72712",
   "metadata": {},
   "source": [
    "COMPUTE_LSTM_IMPORTANCE = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a7e6f87",
   "metadata": {},
   "source": [
    "COLS = list(df_scaled.columns)\n",
    "print(COLS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a55f2ae7",
   "metadata": {},
   "source": [
    "trainX[:,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ec44ccd",
   "metadata": {},
   "source": [
    "print(testY.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9793895",
   "metadata": {},
   "source": [
    "testX[:,:,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a11644f5",
   "metadata": {},
   "source": [
    "values1=values1[:,1:]\n",
    "print(values1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ab988d0",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "if COMPUTE_LSTM_IMPORTANCE:\n",
    "            results = []\n",
    "            print(' Computing LSTM feature importance...')\n",
    "            \n",
    "            # COMPUTE BASELINE (NO SHUFFLE)\n",
    "            oof_preds = model.predict(testX, verbose=0).squeeze() \n",
    "            print(oof_preds.shape)\n",
    "            print(testY.shape)\n",
    "            baseline_mae = np.mean(np.abs( oof_preds-testY ))\n",
    "            results.append({'feature':'BASELINE','mae':baseline_mae})           \n",
    "\n",
    "            for k in tqdm(range(len(COLS)-1)):\n",
    "                \n",
    "                # SHUFFLE FEATURE K\n",
    "                save_col = values1[train_size:len(dX),k].copy()\n",
    "                print(save_col.shape)\n",
    "                np.random.shuffle(testX[:,k])\n",
    "                        \n",
    "                # COMPUTE OOF MAE WITH FEATURE K SHUFFLED\n",
    "                oof_preds = model.predict(testX, verbose=0).squeeze()\n",
    "                print(oof_preds.shape)\n",
    "                print(testY.shape)\n",
    "                mae = np.mean(np.abs( oof_preds-testY ))\n",
    "                results.append({'feature':COLS[k],'mae':mae})\n",
    "                testY = save_col\n",
    "         \n",
    "            # DISPLAY LSTM FEATURE IMPORTANCE\n",
    "            print()\n",
    "            df = pd.DataFrame(results)\n",
    "            df = df.sort_values('mae')\n",
    "            plt.figure(figsize=(10,20))\n",
    "            plt.barh(np.arange(len(COLS)),df.mae)\n",
    "            plt.yticks(np.arange(len(COLS)),df.feature.values)\n",
    "            plt.title('LSTM Feature Importance',size=16)\n",
    "            plt.ylim((-1,len(COLS)+1))\n",
    "            plt.plot([baseline_mae,baseline_mae],[-1,len(COLS)], '--', color='orange',\n",
    "                     label=f'Baseline OOF\\nMAE={baseline_mae:.3f}')\n",
    "            plt.ylabel('Feature',size=14)\n",
    "            plt.legend()\n",
    "            plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
